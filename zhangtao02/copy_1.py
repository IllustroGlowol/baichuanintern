# import json
# import os
# import shutil
# from tqdm import tqdm  # å¼•å…¥ tqdm åº“ç”¨äºè¿›åº¦æ¡
# from concurrent.futures import ThreadPoolExecutor  # ç”¨äºå¹¶è¡ŒåŒ–æ“ä½œ

# # åŸæ–‡ä»¶è·¯å¾„
# input_file_path = "/data_train/code/mllm/zcl/data_construct/100w_mcts_pre.jsonl"
# # ç›®æ ‡ç›®å½•
# output_base_dir = "/global_data/mllm/zcl"
# # è·³è¿‡æ–‡ä»¶çš„æ—¥å¿—è·¯å¾„
# skip_log_path = "/global_data/mllm/zcl/skipped_files.log"

# # ç›®æ ‡è·¯å¾„çš„æ–‡ä»¶å¤¹åˆ›å»º
# def create_target_directory(file_path):
#     target_dir = os.path.dirname(file_path)
#     if not os.path.exists(target_dir):
#         os.makedirs(target_dir)

# # å¤åˆ¶å›¾ç‰‡
# def copy_image(src_path, dest_path, skip_log):
#     # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶
#     if os.path.exists(dest_path):
#         return f"ç›®æ ‡æ–‡ä»¶ {dest_path} å·²å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶ã€‚"

#     # å¦‚æœæºæ–‡ä»¶å­˜åœ¨ï¼Œè¿›è¡Œå¤åˆ¶
#     if os.path.exists(src_path):
#         create_target_directory(dest_path)  # åˆ›å»ºç›®æ ‡æ–‡ä»¶å¤¹
#         shutil.copy(src_path, dest_path)  # å¤åˆ¶æ–‡ä»¶
#         return f"å›¾ç‰‡ {src_path} å·²å¤åˆ¶åˆ° {dest_path}"
#     else:
#         # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
#         with open(skip_log, 'a', encoding='utf-8') as log_file:
#             log_file.write(f"æºæ–‡ä»¶ {src_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶ã€‚\n")
#         return f"æºæ–‡ä»¶ {src_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶ã€‚"

# # è¯»å– JSONL æ–‡ä»¶å¹¶å¤„ç†æ¯ä¸€æ¡è®°å½•
# def process_file_line(line, skip_log_path, output_base_dir):
#     try:
#         record = json.loads(line)  # è§£æ JSON æ•°æ®
#         image_paths = record.get("image", [])
        
#         results = []
#         for image_path in image_paths:
#             if image_path:
#                 # ä¿æŒè·¯å¾„ç»“æ„ä¸å˜ï¼Œç›´æ¥æ‹¼æ¥åˆ°ç›®æ ‡ç›®å½•
#                 target_path = os.path.join(output_base_dir, image_path.lstrip('/data_train/mllm/lichong_02'))
                
#                 # å¤åˆ¶å›¾ç‰‡åˆ°ç›®æ ‡è·¯å¾„
#                 result = copy_image(image_path, target_path, skip_log_path)
#                 results.append(result)
#         return results
#     except json.JSONDecodeError:
#         return [f"è·³è¿‡è§£æé”™è¯¯çš„è¡Œ: {line}"]

# # è¯»å– JSONL æ–‡ä»¶å¹¶å¹¶è¡Œå¤„ç†
# def process_all_files(input_file_path, skip_log_path, output_base_dir):
#     with open(input_file_path, 'r', encoding='utf-8') as f:
#         lines = f.readlines()  # ä¸€æ¬¡æ€§è¯»å–æ‰€æœ‰è¡Œ
#         total_lines = len(lines)  # è®¡ç®—æ€»è¡Œæ•°

#         with tqdm(total=total_lines, desc="Processing images") as pbar:
#             with ThreadPoolExecutor() as executor:  # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†æ–‡ä»¶
#                 futures = []
#                 for line in lines:
#                     future = executor.submit(process_file_line, line, skip_log_path, output_base_dir)
#                     futures.append(future)

#                 # è·å–çº¿ç¨‹æ‰§è¡Œçš„ç»“æœå¹¶æ›´æ–°è¿›åº¦æ¡
#                 for future in futures:
#                     results = future.result()
#                     pbar.update(1)  # æ›´æ–°è¿›åº¦æ¡
#                     for result in results:
#                         print(result)

# # æ‰§è¡Œæ–‡ä»¶å¤„ç†
# process_all_files(input_file_path, skip_log_path, output_base_dir)
# import os
# import json

# # è¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„
# input_path = "/data_train/code/mllm/zhangtao02/EDUBench/data/3w.jsonl"
# output_path = "/data_train/code/mllm/zhangtao02/EDUBench/data/3w_modified.jsonl"

# old_prefix = "/data_train/mllm/lichong_02/afanti_all/qmat/chemistry-g12/pictures/"
# new_prefix = "/data_train/code/mllm/lichong/EDUBench/data/pictures/"

# with open(input_path, "r", encoding="utf-8") as fin, \
#      open(output_path, "w", encoding="utf-8") as fout:
#     for line in fin:
#         try:
#             sample = json.loads(line)
#             if "image" in sample and sample["image"].startswith(old_prefix):
#                 sample["image"] = sample["image"].replace(old_prefix, new_prefix, 1)
#             fout.write(json.dumps(sample, ensure_ascii=False) + "\n")
#         except Exception as e:
#             print(f"[è§£æå¤±è´¥] {e}")
# import json

# # å®šä¹‰æ–‡ä»¶è·¯å¾„
# input_file_path = '/data_train/code/mllm/zcl/llamafactory/data/llavacot100w.jsonl'
# output_file_path = '/data_train/code/mllm/zcl/llamafactory/data/modified_raw100w.jsonl'

# # è¯»å–æ–‡ä»¶å¹¶è¿›è¡Œä¿®æ”¹
# with open(input_file_path, 'r', encoding='utf-8') as infile, open(output_file_path, 'w', encoding='utf-8') as outfile:
#     for line in infile:
#         try:
#             # åŠ è½½å½“å‰è¡Œçš„ JSON æ•°æ®
#             data = json.loads(line)
            
#             # ä¿®æ”¹ images ä¸­çš„è·¯å¾„å‰ç¼€
#             if 'images' in data:
#                 data['images'] = [img.replace('/data_train/mllm/lichong_02/afanti_all/', '/global_data/mllm/zcl/afanti_all/') for img in data['images']]
            
#             # å†™å…¥ä¿®æ”¹åçš„æ•°æ®
#             outfile.write(json.dumps(data, ensure_ascii=False) + '\n')
#         except json.JSONDecodeError as e:
#             print(f"Error decoding JSON: {e}")
#         except Exception as e:
#             print(f"Error processing line: {e}")
import json
import os

# é…ç½®
# input_path = "/data_train/code/mllm/zcl/llamafactory/data/llavacot100w.jsonl"
input_path = "/data_train/code/mllm/zcl/llamafactory/data/raw100w.jsonl"
temp_path = input_path + ".tmp"  # ä¸´æ—¶æ–‡ä»¶è·¯å¾„
target_image = "/global_data/mllm/zcl/afanti_all/qmat/geography-g12/pictures/2023-10-31-geography-g12-00007_c17077e8b553970e02a85424fabfac86.png"

removed, kept = 0, 0

with open(input_path, "r", encoding="utf-8") as fin, \
     open(temp_path, "w", encoding="utf-8") as fout:
    for line in fin:
        try:
            sample = json.loads(line)
            if "images" in sample and target_image in sample["images"]:
                removed += 1
                continue
            fout.write(json.dumps(sample, ensure_ascii=False) + "\n")
            kept += 1
        except Exception:
            continue

# æ›¿æ¢åŸæ–‡ä»¶
os.replace(temp_path, input_path)

print(f"âœ… è¦†ç›–å®Œæˆï¼šå·²ä»åŸæ–‡ä»¶ä¸­ç§»é™¤ {removed} æ¡æ ·æœ¬ï¼Œä¿ç•™ {kept} æ¡ã€‚")

# import os
# import json
# from tqdm import tqdm

# # === é…ç½®è·¯å¾„ ===
# jsonl_path = "/data_train/code/mllm/zcl/llamafactory/data/raw100w.jsonl"
# root_image_dir = "/global_data/mllm/zcl/afanti_all/qmat"
# output_path = jsonl_path.replace(".jsonl", "_no_missing_image.jsonl")
# missing_path = jsonl_path.replace(".jsonl", "_missing_images.jsonl")

# # === ç¬¬ä¸€æ­¥ï¼šæ„å»ºç°æœ‰å›¾ç‰‡è·¯å¾„å…¨é›† ===
# print("ğŸ“‚ æ­£åœ¨æ‰«æå®é™…å­˜åœ¨çš„å›¾ç‰‡è·¯å¾„...")
# existing_images = set()
# for root, _, files in os.walk(root_image_dir):
#     for fname in files:
#         if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.webp')):
#             full_path = os.path.join(root, fname)
#             existing_images.add(full_path)

# print(f"âœ… å›¾ç‰‡æ‰«æå®Œæˆï¼Œå…± {len(existing_images)} å¼ å›¾ç‰‡å­˜åœ¨ã€‚")

# # === ç¬¬äºŒæ­¥ï¼šæ¸…æ´— JSONL æ ·æœ¬ ===
# kept, removed = 0, 0

# with open(jsonl_path, "r", encoding="utf-8") as fin, \
#      open(output_path, "w", encoding="utf-8") as fout_ok, \
#      open(missing_path, "w", encoding="utf-8") as fout_bad:

#     for line in tqdm(fin, desc="è¿‡æ»¤å«ç¼ºå¤±å›¾ç‰‡çš„æ ·æœ¬"):
#         try:
#             sample = json.loads(line)
#             imgs = sample.get("images", [])
#             if not isinstance(imgs, list):
#                 imgs = []

#             if any(img_path not in existing_images for img_path in imgs):
#                 fout_bad.write(json.dumps(sample, ensure_ascii=False) + "\n")
#                 removed += 1
#             else:
#                 fout_ok.write(json.dumps(sample, ensure_ascii=False) + "\n")
#                 kept += 1
#         except Exception:
#             removed += 1

# print(f"\nğŸ‰ æ¸…æ´—å®Œæˆï¼šä¿ç•™ {kept} æ¡ï¼Œç§»é™¤ {removed} æ¡ã€‚")
# print(f"âœ” åˆæ³•æ ·æœ¬ä¿å­˜åˆ°ï¼š{output_path}")
# print(f"âš  ç¼ºå¤±å›¾ç‰‡æ ·æœ¬ä¿å­˜åˆ°ï¼š{missing_path}")

# import os
# import json
# from tqdm import tqdm

# # è·¯å¾„é…ç½®
# cleaned_jsonl = "/data_train/code/mllm/zcl/llamafactory/data/llavacot100w.jsonl"
# root_image_dir = "/global_data/mllm/zcl/afanti_all/qmat"

# # åŠ è½½ç°æœ‰å›¾ç‰‡è·¯å¾„
# print("é‡æ–°åŠ è½½æ‰€æœ‰å­˜åœ¨å›¾ç‰‡è·¯å¾„è¿›è¡ŒéªŒè¯...")
# existing_images = set()
# for root, _, files in os.walk(root_image_dir):
#     for fname in files:
#         if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.webp', '.gif','.bmp')):
#             existing_images.add(os.path.join(root, fname))

# print(f"å›¾ç‰‡åŠ è½½å®Œæˆï¼Œå…± {len(existing_images)} å¼ ã€‚")

# # éªŒè¯ JSONL æ˜¯å¦è¿˜æœ‰æœªè¢«æ¸…ç†å¹²å‡€çš„
# residual_bad = []
# with open(cleaned_jsonl, "r", encoding="utf-8") as f:
#     for idx, line in enumerate(tqdm(f, desc="äºŒæ¬¡éªŒè¯æ ·æœ¬ä¸­å›¾ç‰‡æ˜¯å¦éƒ½å­˜åœ¨")):
#         try:
#             data = json.loads(line)
#             imgs = data.get("images", [])
#             if any(p not in existing_images for p in imgs):
#                 residual_bad.append((idx, imgs))
#         except Exception:
#             continue

# if residual_bad:
#     print(f"\nè­¦å‘Šï¼šå‘ç° {len(residual_bad)} æ¡æ ·æœ¬ä¸­ä»å«ä¸å­˜åœ¨çš„å›¾ç‰‡è·¯å¾„ï¼Œä¾‹å¦‚ï¼š")
#     for i, paths in residual_bad[:5]:
#         print(f"  - è¡Œ {i}: ç¼ºå¤±è·¯å¾„ç¤ºä¾‹ {paths}")
# else:
#     print("\néªŒè¯é€šè¿‡ï¼šæ‰€æœ‰æ ·æœ¬å¼•ç”¨çš„å›¾ç‰‡è·¯å¾„éƒ½å­˜åœ¨ï¼Œæ£€æŸ¥å½»åº•å®Œæˆï¼")

